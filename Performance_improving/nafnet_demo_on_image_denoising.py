# -*- coding: utf-8 -*-
"""NAFNet demo on Image Denoisingì˜ ì‚¬ë³¸

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jD-72NUOphavyffC86lba635GtaadThq

# NAFNet Online Demo on Image Denoising

## Git clone [NAFNet](https://github.com/megvii-research/NAFNet) repo
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/megvii-research/NAFNet
# %cd NAFNet

"""## Set up the enviroment"""

!pip install -r requirements.txt
!pip install --upgrade --no-cache-dir gdown
!python3 setup.py develop --no_cuda_ext

"""## Download pretrained models"""

import gdown
gdown.download('https://drive.google.com/uc?id=14Fht1QQJ2gMlk4N1ERCRuElg8JfjrWWR', "./experiments/pretrained_models/", quiet=False)

"""## Download Demo Image"""

gdown.download('https://drive.google.com/uc?id=1uKwZUgeGfBYLlPKllSuzgGUItlzb40hm', "demo_input/", quiet=False)
gdown.download('https://drive.google.com/uc?id=1ov6UqpIA6GjjJT5SdGeUAJECxka14nGf', "demo_input/", quiet=False)

"""## Preparation"""

import torch

from basicsr.models import create_model
from basicsr.utils import img2tensor as _img2tensor, tensor2img, imwrite
from basicsr.utils.options import parse
import numpy as np
import cv2
import matplotlib.pyplot as plt

def imread(img_path):
  img = cv2.imread(img_path)
  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
  return img
def img2tensor(img, bgr2rgb=False, float32=True):
    img = img.astype(np.float32) / 255.
    return _img2tensor(img, bgr2rgb=bgr2rgb, float32=float32)

def display(img1, img2):
  fig = plt.figure(figsize=(25, 10))
  ax1 = fig.add_subplot(1, 2, 1)
  plt.title('Input image', fontsize=16)
  ax1.axis('off')
  ax2 = fig.add_subplot(1, 2, 2)
  plt.title('NAFNet output', fontsize=16)
  ax2.axis('off')
  ax1.imshow(img1)
  ax2.imshow(img2)

def single_image_inference(model, img, save_path):
      model.feed_data(data={'lq': img.unsqueeze(dim=0)})

      if model.opt['val'].get('grids', False):
          model.grids()

      model.test()

      if model.opt['val'].get('grids', False):
          model.grids_inverse()

      visuals = model.get_current_visuals()
      sr_img = tensor2img([visuals['result']])
      imwrite(sr_img, save_path)

"""## Create Model"""

opt_path = 'options/test/SIDD/NAFNet-width64.yml'
opt = parse(opt_path, is_train=False)
opt['dist'] = False
NAFNet = create_model(opt)

"""# Inference and Show results"""

input_path = 'demo_input/noisy-demo-0.png'
output_path = 'demo_output/noisy-demo-0.png'

img_input = imread(input_path)
inp = img2tensor(img_input)
single_image_inference(NAFNet, inp, output_path)
img_output = imread(output_path)
display(img_input, img_output)

!pip install lpips

!ls -R upload

import math
import numpy as np
import torch
import lpips
from imageio import imread

def calculate_psnr(img1, img2):
    """
    img1, img2: numpy array, RGB, uint8 ë˜ëŠ” float32 [0,255]
    """
    img1 = img1.astype(np.float32)
    img2 = img2.astype(np.float32)
    mse = np.mean((img1 - img2) ** 2)
    if mse == 0:
        return float('inf')
    PIXEL_MAX = 255.0
    psnr = 20 * math.log10(PIXEL_MAX / math.sqrt(mse))
    return psnr

# ====================================================
# 2) SSIM
# ====================================================
def calculate_ssim(img1, img2):
    """
    img1, img2: numpy array, RGB, uint8 [0,255]
    """
    img1 = img1.astype(np.float32)
    img2 = img2.astype(np.float32)

    # RGB â†’ Grayscale (SSIMì€ ì£¼ë¡œ grayë¡œ ê³„ì‚°)
    img1 = cv2.cvtColor(img1, cv2.COLOR_RGB2GRAY)
    img2 = cv2.cvtColor(img2, cv2.COLOR_RGB2GRAY)

    # SSIM ê³µì‹ êµ¬í˜„
    C1 = (0.01 * 255) ** 2
    C2 = (0.03 * 255) ** 2

    mu1 = cv2.GaussianBlur(img1, (11, 11), 1.5)
    mu2 = cv2.GaussianBlur(img2, (11, 11), 1.5)

    mu1_sq = mu1 * mu1
    mu2_sq = mu2 * mu2
    mu1_mu2 = mu1 * mu2

    sigma1_sq = cv2.GaussianBlur(img1 * img1, (11, 11), 1.5) - mu1_sq
    sigma2_sq = cv2.GaussianBlur(img2 * img2, (11, 11), 1.5) - mu2_sq
    sigma12   = cv2.GaussianBlur(img1 * img2, (11, 11), 1.5) - mu1_mu2

    ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / \
               ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))

    return ssim_map.mean()


# -------------------------
# LPIPS ê³„ì‚° í•¨ìˆ˜
# -------------------------
lpips_model = lpips.LPIPS(net="alex").cuda()  # CPUë©´ .cuda() ì œê±°!

def calculate_lpips(img1, img2):
    """
    img1, img2: numpy array RGB, uint8 [0,255]
    LPIPS ê³„ì‚°ì„ ìœ„í•´ torch tensorë¡œ ë³€í™˜
    """
    # [H,W,3] â†’ [1,3,H,W] ë¡œ ë³€í™˜ í›„ [-1,1] ë²”ìœ„ë¡œ ì •ê·œí™”
    t1 = torch.tensor(img1).permute(2,0,1).float().unsqueeze(0) / 255.0
    t2 = torch.tensor(img2).permute(2,0,1).float().unsqueeze(0) / 255.0

    t1 = (t1 * 2) - 1
    t2 = (t2 * 2) - 1

    t1 = t1.cuda()
    t2 = t2.cuda()

    with torch.no_grad():
        dist = lpips_model(t1, t2)

    return dist.item()

# ===========================
# í´ë” ê²½ë¡œ ì •ì˜
# ===========================
input_dir = "upload/input/jpeg"
gt_dir = "upload/input/gt"
output_dir = "upload/output"

# ===========================
# ê³µí†µ íŒŒì¼ëª… ëª©ë¡ (input ê¸°ì¤€)
# ===========================
input_files = sorted([
    f for f in os.listdir(input_dir)
    if f.lower().endswith((".png", ".jpg", ".jpeg"))
])

print("ì²˜ë¦¬í•  íŒŒì¼ ê°œìˆ˜:", len(input_files))

psnr_input_list = []
psnr_output_list = []
lpips_input_list = []
lpips_output_list = []
ssim_input_list = []
ssim_output_list = []

# ===========================
# íŒŒì¼ ìˆœíšŒ (1:1 ë§¤ì¹­)
# ===========================
for filename in input_files:
    input_path = os.path.join(input_dir, filename)
    gt_path = os.path.join(gt_dir, filename)
    output_path = os.path.join(output_dir, filename)


      # -------------------------
    # 1) ì´ë¯¸ì§€ ì½ê¸°
    # -------------------------
    img_input = imread(input_path)

    # -------------------------
    # 2) NAFNet ì¶”ë¡  (Output ìƒì„±)
    # -------------------------
    inp = img2tensor(img_input)
    single_image_inference(NAFNet, inp, output_path)

    # GT / Output ì—†ëŠ” ê²½ìš° ìŠ¤í‚µ
    if not os.path.exists(gt_path):
        print(f"âš  GT ì—†ìŒ: {filename}, ìŠ¤í‚µ")
        continue
    if not os.path.exists(output_path):
        print(f"âš  Output ì—†ìŒ: {filename}, ìŠ¤í‚µ")
        continue

    img_input = imread(input_path)
    img_gt = imread(gt_path)
    img_output = imread(output_path)

    # PSNR
    psnr_in = calculate_psnr(img_gt, img_input)
    psnr_out = calculate_psnr(img_gt, img_output)

    # SSIM
    ssim_in = calculate_ssim(img_gt, img_input)
    ssim_out = calculate_ssim(img_gt, img_output)

    # LPIPS
    lpips_in = calculate_lpips(img_gt, img_input)
    lpips_out = calculate_lpips(img_gt, img_output)

    psnr_input_list.append(psnr_in)
    psnr_output_list.append(psnr_out)
    ssim_input_list.append(ssim_in)
    ssim_output_list.append(ssim_out)
    lpips_input_list.append(lpips_in)
    lpips_output_list.append(lpips_out)

    print(f"\n=== {filename} ===")
    print(f"PSNR  Input : {psnr_in:.4f}")
    print(f"PSNR  Output: {psnr_out:.4f}")
    print(f"SSIM  Input : {ssim_in:.4f}")
    print(f"SSIM  Output: {ssim_out:.4f}")
    print(f"LPIPS Input : {lpips_in:.4f}")
    print(f"LPIPS Output: {lpips_out:.4f}")

# ===========================
# ì „ì²´ í‰ê·  ì¶œë ¥
# ===========================
print("\n==============================")
print("ğŸ“Š ì „ì²´ í‰ê·  ê²°ê³¼")
print("==============================")

print(f"í‰ê·  PSNR (Input):  {np.mean(psnr_input_list):.4f} dB")
print(f"í‰ê·  PSNR (Output): {np.mean(psnr_output_list):.4f} dB")

print(f"í‰ê·  SSIM (Input):  {np.mean(ssim_input_list):.4f}")
print(f"í‰ê·  SSIM (Output): {np.mean(ssim_output_list):.4f}")

print(f"í‰ê·  LPIPS (Input):  {np.mean(lpips_input_list):.4f}")
print(f"í‰ê·  LPIPS (Output): {np.mean(lpips_output_list):.4f}")

"""# Try it on uploaded images

## 1. Upload images
"""

import os
from google.colab import files
import shutil

upload_folder = 'upload/input/gt'
result_folder = 'upload/output'

os.makedirs(upload_folder, exist_ok=True)
os.makedirs(result_folder, exist_ok=True)

# upload images
uploaded = files.upload()
for filename in uploaded.keys():
  dst_path = os.path.join(upload_folder, filename)
  print(f'move {filename} to {dst_path}')
  shutil.move(filename, dst_path)



"""## Inference"""

import glob
input_list = sorted(glob.glob(os.path.join(upload_folder, '*')))
for input_path in input_list:
  img_input = imread(input_path)
  inp = img2tensor(img_input)
  output_path = os.path.join(result_folder, os.path.basename(input_path))
  single_image_inference(NAFNet, inp, output_path)

"""## 3. Visualize (Optional)"""

# visualize
input_list = sorted(glob.glob(os.path.join(upload_folder, '*')))
output_list = sorted(glob.glob(os.path.join(result_folder, '*')))
for input_path, output_path in zip(input_list, output_list):
  img_input = imread(input_path)
  img_output = imread(output_path)
  display(img_input, img_output)

"""## 4. Download results"""

# download the result
print(f'Download {result_folder}')
os.system(f'zip -r -j download.zip {result_folder}/*')
files.download("download.zip")